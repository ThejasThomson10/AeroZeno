{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FOR VIDEO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import torch\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Path to the custom-trained YOLOv8 model\n",
    "model_path = r\"C:\\Users\\theja\\runs\\detect\\train4\\weights\\best.pt\"\n",
    "model = YOLO(model_path)  # Load the trained model\n",
    "\n",
    "# Path to the uploaded video\n",
    "video_path = r\"image_20250305-121446.png\"  # Change to your video path\n",
    "\n",
    "# Open the video file\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "# Get video properties\n",
    "frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "\n",
    "# Create a VideoWriter to save the processed video\n",
    "output_video_path = \"surveyed_zebra_video.mp4\"\n",
    "fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")\n",
    "out = cv2.VideoWriter(output_video_path, fourcc, fps, (frame_width, frame_height))\n",
    "\n",
    "# Total count storage\n",
    "zebra_count = 0\n",
    "other_animals = {}\n",
    "\n",
    "# Process video frame by frame\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Run YOLO object detection\n",
    "    results = model(frame)\n",
    "\n",
    "    # Frame-wise count\n",
    "    frame_zebra_count = 0\n",
    "    frame_other_animals = set()\n",
    "\n",
    "    # Process results\n",
    "    for result in results:\n",
    "        for box in result.boxes:\n",
    "            cls_id = int(box.cls[0])  # Ensure correct class index extraction\n",
    "            conf = float(box.conf[0])  # Confidence score\n",
    "            label = model.names[cls_id].strip().lower()  # Normalize class name\n",
    "\n",
    "            # Draw bounding box\n",
    "            x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
    "            color = (0, 255, 0) if label == \"zebra\" else (255, 0, 0)\n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), color, 2)\n",
    "            cv2.putText(frame, f\"{label} {conf:.2f}\", (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
    "\n",
    "            # Count zebras and other animals correctly\n",
    "            if label == \"zebra\":\n",
    "                frame_zebra_count += 1\n",
    "            else:\n",
    "                frame_other_animals.add(label)\n",
    "                other_animals[label] = other_animals.get(label, 0) + 1\n",
    "\n",
    "    zebra_count += frame_zebra_count\n",
    "\n",
    "    # Display count on video frame\n",
    "    cv2.putText(frame, f\"Zebras in Frame: {frame_zebra_count}\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "    cv2.putText(frame, f\"Total Zebras: {zebra_count}\", (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "    cv2.putText(frame, f\"Other Animals: {', '.join(frame_other_animals)}\", (10, 90), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2)\n",
    "\n",
    "    # Save frame to output video\n",
    "    out.write(frame)\n",
    "\n",
    "    # Display video frame\n",
    "    cv2.imshow(\"Zebra Survey\", frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# Print final counts\n",
    "print(f\"Total Zebras detected: {zebra_count}\")\n",
    "print(\"Other animals detected:\")\n",
    "for animal, count in other_animals.items():\n",
    "    print(f\"{animal}: {count}\")\n",
    "\n",
    "print(f\"Processed video saved as {output_video_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FOR IMAGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import torch\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Path to the custom-trained YOLOv8 model\n",
    "model_path = r\"C:\\Users\\theja\\runs\\detect\\train4\\weights\\best.pt\"\n",
    "model = YOLO(model_path)  # Load the trained model\n",
    "\n",
    "# Path to the uploaded image\n",
    "image_path = r\"image_20250305-121545.png\"\n",
    "image = cv2.imread(image_path)\n",
    "\n",
    "# Run YOLO object detection\n",
    "results = model(image)\n",
    "\n",
    "# Total count storage\n",
    "zebra_count = 0\n",
    "other_animals = {}\n",
    "\n",
    "# Process results\n",
    "for result in results:\n",
    "    for box in result.boxes:\n",
    "        cls_id = int(box.cls[0])  # Extract class index correctly\n",
    "        conf = float(box.conf[0])  # Confidence score\n",
    "        label = model.names[cls_id].strip().lower()  # Normalize class name\n",
    "\n",
    "        # Draw bounding box\n",
    "        x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
    "        color = (0, 255, 0) if label == \"zebra\" else (255, 0, 0)\n",
    "        cv2.rectangle(image, (x1, y1), (x2, y2), color, 2)\n",
    "        cv2.putText(image, f\"{label} {conf:.2f}\", (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
    "\n",
    "        # Count zebras and other animals correctly\n",
    "        if label == \"zebra\":\n",
    "            zebra_count += 1\n",
    "        else:\n",
    "            other_animals[label] = other_animals.get(label, 0) + 1\n",
    "\n",
    "# Display count on image\n",
    "cv2.putText(image, f\"Total Zebras: {zebra_count}\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "cv2.putText(image, f\"Other Animals: {', '.join(other_animals.keys())}\", (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2)\n",
    "\n",
    "# Save the processed image\n",
    "output_image_path = \"surveyed_zebra_image.png\"\n",
    "cv2.imwrite(output_image_path, image)\n",
    "\n",
    "# Print final counts\n",
    "print(f\"Total Zebras detected: {zebra_count}\")\n",
    "print(\"Other animals detected:\")\n",
    "for animal, count in other_animals.items():\n",
    "    print(f\"{animal}: {count}\")\n",
    "\n",
    "print(f\"Processed image saved as {output_image_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TO GET FRAMES FROM VIDEO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "video_path = \"video.mp4\"\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "frame_count = 0\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    cv2.imwrite(f\"dataset/images/frame_{frame_count}.jpg\", frame)\n",
    "    frame_count += 1\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VIDEO WITH QUADRANT INFORMATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import cv2\n",
    "import torch\n",
    "from ultralytics import YOLO\n",
    "\n",
    "model_path = r\"C:\\Users\\theja\\runs\\detect\\train4\\weights\\best.pt\"\n",
    "model = YOLO(model_path)  # Load the trained model\n",
    "\n",
    "video_path = r\"image_20250305-121446.png\"  # Change to your video path\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "\n",
    "output_video_path = \"surveyed_zebra_video.mp4\"\n",
    "fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")\n",
    "out = cv2.VideoWriter(output_video_path, fourcc, fps, (frame_width, frame_height))\n",
    "\n",
    "\n",
    "total_zebra_count = 0\n",
    "total_elephant_count = 0\n",
    "elephant_quadrants_overall = set()\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    mid_x = frame_width // 2\n",
    "    mid_y = frame_height // 2\n",
    "    cv2.line(frame, (mid_x, 0), (mid_x, frame_height), (255, 255, 255), 2)\n",
    "    cv2.line(frame, (0, mid_y), (frame_width, mid_y), (255, 255, 255), 2)\n",
    "\n",
    "    results = model(frame)\n",
    "    \n",
    "    frame_zebra_count = 0\n",
    "    frame_elephant_count = 0\n",
    "    frame_elephant_quadrants = set()\n",
    "    frame_other_animals = {} \n",
    "    for result in results:\n",
    "        for box in result.boxes:\n",
    "       \n",
    "            cls_id = int(box.cls[0])     \n",
    "            conf = float(box.conf[0])      \n",
    "            label = model.names[cls_id].strip().lower()\n",
    "\n",
    "            x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
    "            \n",
    "    \n",
    "            color = (0, 255, 0) if label == \"zebra\" else (255, 0, 0)\n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), color, 2)\n",
    "            cv2.putText(frame, f\"{label} {conf:.2f}\", (x1, y1 - 10),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
    "\n",
    "            if label == \"zebra\":\n",
    "                frame_zebra_count += 1\n",
    "            elif label == \"elephant\":\n",
    "                frame_elephant_count += 1\n",
    "        \n",
    "                center_x = (x1 + x2) // 2\n",
    "                center_y = (y1 + y2) // 2\n",
    "   \n",
    "                if center_x < mid_x and center_y < mid_y:\n",
    "                    quadrant = \"Top Left\"\n",
    "                elif center_x >= mid_x and center_y < mid_y:\n",
    "                    quadrant = \"Top Right\"\n",
    "                elif center_x < mid_x and center_y >= mid_y:\n",
    "                    quadrant = \"Bottom Left\"\n",
    "                else:\n",
    "                    quadrant = \"Bottom Right\"\n",
    "                frame_elephant_quadrants.add(quadrant)\n",
    "\n",
    "                cv2.putText(frame, f\"{label} ({quadrant})\", (x1, y1 - 25),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 2)\n",
    "            else:\n",
    "\n",
    "                frame_other_animals[label] = frame_other_animals.get(label, 0) + 1\n",
    "\n",
    "\n",
    "    total_zebra_count += frame_zebra_count\n",
    "    total_elephant_count += frame_elephant_count\n",
    "    elephant_quadrants_overall.update(frame_elephant_quadrants)\n",
    "\n",
    "    cv2.putText(frame, f\"Zebras in Frame: {frame_zebra_count}\", (10, 30),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "    cv2.putText(frame, f\"Total Zebras: {total_zebra_count}\", (10, 60),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "    other_animals_text = \", \".join([f\"{k}: {v}\" for k, v in frame_other_animals.items()])\n",
    "    cv2.putText(frame, f\"Others: {other_animals_text}\", (10, 90),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2)\n",
    "\n",
    "    out.write(frame)\n",
    "    cv2.imshow(\"Zebra Survey\", frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "print(f\"Total Zebras detected: {total_zebra_count}\")\n",
    "print(f\"Total Elephants detected: {total_elephant_count}\")\n",
    "print(\"Other animals detected:\")\n",
    "for animal, count in frame_other_animals.items():\n",
    "    print(f\"{animal}: {count}\")\n",
    "if elephant_quadrants_overall:\n",
    "    print(\"Elephant(s) detected in quadrant(s): \" + \", \".join(elephant_quadrants_overall))\n",
    "else:\n",
    "    print(\"No elephant detected.\")\n",
    "\n",
    "print(f\"Processed video saved as {output_video_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMAGE WITH QUADRANT INFORMATION "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import torch\n",
    "from ultralytics import YOLO\n",
    "\n",
    "model_path = r\"C:\\Users\\theja\\runs\\detect\\train4\\weights\\best.pt\"\n",
    "model = YOLO(model_path)  # Load the trained model\n",
    "\n",
    "\n",
    "image_path = r\"image_20250305-121545.png\"\n",
    "image = cv2.imread(image_path)\n",
    "\n",
    "\n",
    "height, width, _ = image.shape\n",
    "mid_x = width // 2\n",
    "mid_y = height // 2\n",
    "\n",
    "\n",
    "cv2.line(image, (mid_x, 0), (mid_x, height), (255, 255, 255), 2)\n",
    "cv2.line(image, (0, mid_y), (width, mid_y), (255, 255, 255), 2)\n",
    "\n",
    "\n",
    "zebra_count = 0\n",
    "other_animals = {}\n",
    "elephant_quadrants = set() \n",
    "\n",
    "results = model(image)\n",
    "\n",
    "for result in results:\n",
    "    for box in result.boxes:\n",
    "        cls_id = int(box.cls[0])\n",
    "        conf = float(box.conf[0]) \n",
    "        label = model.names[cls_id].strip().lower() \n",
    "\n",
    "        x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
    "        color = (0, 255, 0) if label == \"zebra\" else (255, 0, 0)\n",
    "        cv2.rectangle(image, (x1, y1), (x2, y2), color, 2)\n",
    "        cv2.putText(image, f\"{label} {conf:.2f}\", (x1, y1 - 10),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
    "\n",
    "\n",
    "        if label == \"zebra\":\n",
    "            zebra_count += 1\n",
    "        else:\n",
    "            other_animals[label] = other_animals.get(label, 0) + 1\n",
    "\n",
    "\n",
    "        if label == \"elephant\":\n",
    "        \n",
    "            center_x = (x1 + x2) // 2\n",
    "            center_y = (y1 + y2) // 2\n",
    "\n",
    "    \n",
    "            if center_x < mid_x and center_y < mid_y:\n",
    "                quadrant = \"Top Left\"\n",
    "            elif center_x >= mid_x and center_y < mid_y:\n",
    "                quadrant = \"Top Right\"\n",
    "            elif center_x < mid_x and center_y >= mid_y:\n",
    "                quadrant = \"Bottom Left\"\n",
    "            else:\n",
    "                quadrant = \"Bottom Right\"\n",
    "\n",
    "            elephant_quadrants.add(quadrant)\n",
    "            cv2.putText(image, f\"{label} ({quadrant})\", (x1, y1 - 25),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 2)\n",
    "\n",
    "\n",
    "cv2.putText(image, f\"Total Zebras: {zebra_count}\", (10, 30),\n",
    "            cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "other_animals_text = \", \".join([f\"{k}: {v}\" for k, v in other_animals.items()])\n",
    "cv2.putText(image, f\"Other Animals: {other_animals_text}\", (10, 60),\n",
    "            cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2)\n",
    "\n",
    "\n",
    "output_image_path = \"surveyed_zebra_image.png\"\n",
    "cv2.imwrite(output_image_path, image)\n",
    "\n",
    "print(f\"Total Zebras detected: {zebra_count}\")\n",
    "print(\"Other animals detected:\")\n",
    "for animal, count in other_animals.items():\n",
    "    print(f\"{animal}: {count}\")\n",
    "\n",
    "if elephant_quadrants:\n",
    "    print(\"Elephant(s) detected in quadrant(s): \" + \", \".join(elephant_quadrants))\n",
    "else:\n",
    "    print(\"No elephant detected.\")\n",
    "\n",
    "print(f\"Processed image saved as {output_image_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CODE FOR MISSION (YET TO BE TESTED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from pymavlink import mavutil\n",
    "import time\n",
    "import math\n",
    "import cv2\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "import RPi.GPIO as GPIO\n",
    "from picamera2 import Picamera2\n",
    "\n",
    "\n",
    "SERVO_PIN = 17  # Not used here as payload release is manual\n",
    "GPIO.setmode(GPIO.BCM)\n",
    "GPIO.setup(SERVO_PIN, GPIO.OUT)\n",
    "servo = GPIO.PWM(SERVO_PIN, 50) \n",
    "servo.start(0)\n",
    "\n",
    "def get_current_position(mav):\n",
    "    \"\"\"\n",
    "    Retrieves current position from a GLOBAL_POSITION_INT message.\n",
    "    Returns (lat, lon, alt) in degrees and meters.\n",
    "    \"\"\"\n",
    "    msg = mav.recv_match(type='GLOBAL_POSITION_INT', blocking=True, timeout=5)\n",
    "    if msg is None:\n",
    "        return None\n",
    "    lat = msg.lat / 1e7\n",
    "    lon = msg.lon / 1e7\n",
    "    alt = msg.relative_alt / 1000.0  \n",
    "    return (lat, lon, alt)\n",
    "\n",
    "def get_distance_meters(lat1, lon1, lat2, lon2):\n",
    "    \"\"\"\n",
    "    Approximate distance (in meters) between two lat/lon points.\n",
    "    \"\"\"\n",
    "    dlat = lat2 - lat1\n",
    "    dlon = lon2 - lon1\n",
    "    return math.sqrt((dlat * 111320)*2 + (dlon * 111320)*2)\n",
    "\n",
    "def goto_waypoint_mavlink(mav, target_lat, target_lon, target_alt, threshold=2.0, timeout=120):\n",
    "    \"\"\"\n",
    "    Commands the drone to navigate to a waypoint using SET_POSITION_TARGET_GLOBAL_INT.\n",
    "    \"\"\"\n",
    "    print(f\"Navigating to waypoint: lat={target_lat}, lon={target_lon}, alt={target_alt}\")\n",
    "    lat_int = int(target_lat * 1e7)\n",
    "    lon_int = int(target_lon * 1e7)\n",
    "\n",
    "    type_mask = 0b0000111111000111  \n",
    "    start_time = time.time()\n",
    "    while time.time() - start_time < timeout:\n",
    "        mav.mav.set_position_target_global_int_send(\n",
    "            int(time.time() * 1000),  \n",
    "            mav.target_system,\n",
    "            mav.target_component,\n",
    "            mavutil.mavlink.MAV_FRAME_GLOBAL_RELATIVE_ALT_INT,\n",
    "            type_mask,\n",
    "            lat_int,                  \n",
    "            lon_int,                   \n",
    "            target_alt,                \n",
    "            0, 0, 0,                 \n",
    "            0, 0, 0,                  \n",
    "            0, 0)                     \n",
    "        pos = get_current_position(mav)\n",
    "        if pos:\n",
    "            current_lat, current_lon, current_alt = pos\n",
    "            dist = get_distance_meters(current_lat, current_lon, target_lat, target_lon)\n",
    "            print(f\" Distance: {dist:.2f} m, Altitude: {current_alt:.2f} m\")\n",
    "            if dist < threshold:\n",
    "                print(\"Waypoint reached.\")\n",
    "                return True\n",
    "        time.sleep(1)\n",
    "    print(\"Timeout reached.\")\n",
    "    return False\n",
    "\n",
    "def arm_vehicle(mav):\n",
    "    \"\"\"\n",
    "    Arms the vehicle via MAV_CMD_COMPONENT_ARM_DISARM.\n",
    "    \"\"\"\n",
    "    print(\"Arming vehicle...\")\n",
    "    mav.mav.command_long_send(\n",
    "        mav.target_system,\n",
    "        mav.target_component,\n",
    "        mavutil.mavlink.MAV_CMD_COMPONENT_ARM_DISARM,\n",
    "        0,\n",
    "        1, 0, 0, 0, 0, 0, 0)\n",
    "    while True:\n",
    "        heartbeat = mav.recv_match(type='HEARTBEAT', blocking=True, timeout=5)\n",
    "        if heartbeat:\n",
    "            armed = (heartbeat.base_mode & mavutil.mavlink.MAV_MODE_FLAG_SAFETY_ARMED) != 0\n",
    "            if armed:\n",
    "                print(\"Vehicle armed.\")\n",
    "                break\n",
    "        time.sleep(1)\n",
    "\n",
    "def takeoff_vehicle(mav, altitude):\n",
    "\n",
    "    print(f\"Taking off to {altitude} m...\")\n",
    "    mav.mav.command_long_send(\n",
    "        mav.target_system,\n",
    "        mav.target_component,\n",
    "        mavutil.mavlink.MAV_CMD_NAV_TAKEOFF,\n",
    "        0,\n",
    "        0, 0, 0, 0, 0, 0,\n",
    "        altitude)\n",
    "    while True:\n",
    "        pos = get_current_position(mav)\n",
    "        if pos:\n",
    "            current_alt = pos[2]\n",
    "            print(f\" Current altitude: {current_alt:.2f} m\")\n",
    "            if current_alt >= altitude * 0.95:\n",
    "                print(\"Reached target altitude.\")\n",
    "                break\n",
    "        time.sleep(1)\n",
    "\n",
    "def land_vehicle(mav, target_lat, target_lon, target_alt=0):\n",
    "\n",
    "    print(f\"Landing at lat={target_lat}, lon={target_lon}, alt={target_alt}\")\n",
    "    mav.mav.command_long_send(\n",
    "        mav.target_system,\n",
    "        mav.target_component,\n",
    "        mavutil.mavlink.MAV_CMD_NAV_LAND,\n",
    "        0,\n",
    "        0, 0, 0, 0,\n",
    "        target_lat, target_lon, target_alt)\n",
    "    while True:\n",
    "        pos = get_current_position(mav)\n",
    "        if pos:\n",
    "            current_alt = pos[2]\n",
    "            print(f\" Altitude during landing: {current_alt:.2f} m\")\n",
    "            if current_alt <= 1.0:\n",
    "                print(\"Landed.\")\n",
    "                break\n",
    "        time.sleep(1)\n",
    "\n",
    "def capture_photo(filename=\"mission_photo.jpg\"):\n",
    "\n",
    "    print(\"Capturing photo with picamera2...\")\n",
    "    picam2 = Picamera2()\n",
    "  \n",
    "    config = picam2.create_still_configuration()\n",
    "    picam2.configure(config)\n",
    "    picam2.start()\n",
    "    time.sleep(2) \n",
    "    frame = picam2.capture_array() \n",
    "    picam2.stop()\n",
    "    cv2.imwrite(filename, frame)\n",
    "    print(f\"Photo saved as {filename}\")\n",
    "    return filename\n",
    "\n",
    "def process_image_yolo(filename=\"mission_photo.jpg\"):\n",
    "\n",
    "    print(\"Processing image with YOLOv8...\")\n",
    "    model = YOLO(\"best.pt\")\n",
    "    results = model(filename)\n",
    "    img = cv2.imread(filename)\n",
    "    if img is None:\n",
    "        raise Exception(\"Failed to load image.\")\n",
    "    height, width, _ = img.shape\n",
    "    best_detection = None\n",
    "    best_conf = 0.0\n",
    "    for box in results[0].boxes:\n",
    "        coords = box.xyxy[0].cpu().numpy() \n",
    "        conf = float(box.conf.cpu().numpy())\n",
    "        cls = int(box.cls.cpu().numpy())\n",
    "        class_name = model.names[cls].lower() if cls in model.names else \"\"\n",
    "        if class_name == \"elephant\" and conf > best_conf:\n",
    "            best_conf = conf\n",
    "            best_detection = coords\n",
    "    if best_detection is not None:\n",
    "        x1, y1, x2, y2 = best_detection\n",
    "        centerX = (x1 + x2) / 2\n",
    "        centerY = (y1 + y2) / 2\n",
    "       \n",
    "        if centerX >= width/2 and centerY < height/2:\n",
    "            quadrant = \"top_right\"\n",
    "        elif centerX < width/2 and centerY < height/2:\n",
    "            quadrant = \"top_left\"\n",
    "        elif centerX < width/2 and centerY >= height/2:\n",
    "            quadrant = \"bottom_left\"\n",
    "        else:\n",
    "            quadrant = \"bottom_right\"\n",
    "        print(f\"YOLOv8 detected an elephant in: {quadrant}\")\n",
    "        return quadrant\n",
    "    else:\n",
    "        print(\"No elephant detected.\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def main():\n",
    "    \n",
    "    mav = mavutil.mavlink_connection('/dev/ttyAMA0', baud=921600)\n",
    "    print(\"Waiting for heartbeat...\")\n",
    "    mav.wait_heartbeat()\n",
    "    print(f\"Heartbeat received. System ID: {mav.target_system}, Component ID: {mav.target_component}\")\n",
    "    \n",
    "   \n",
    "    survey_waypoints = [\n",
    "        (51.423406, -2.671561, 25),\n",
    "        (51.423169, -2.671393, 25),\n",
    "        (51.422861, -2.671139, 25),\n",
    "        (51.422734, -2.670292, 25),\n",
    "        (51.422666, -2.669438, 25),\n",
    "        (51.422938, -2.669116, 25),\n",
    "        (51.423254, -2.668816, 25),\n",
    "        (51.423639, -2.669082, 25),\n",
    "        (51.423675, -2.669568, 25),\n",
    "        (51.423599, -2.670862, 25)\n",
    "    ]\n",
    "   \n",
    "    survey_midpoint = (51.423552, -2.67100, 25)\n",
    "    \n",
    "    \n",
    "    print(\"Waiting for GPS lock to store takeoff location...\")\n",
    "    takeoff_location = None\n",
    "    while takeoff_location is None:\n",
    "        takeoff_location = get_current_position(mav)\n",
    "        time.sleep(1)\n",
    "    print(f\"Takeoff location stored as: {takeoff_location}\")\n",
    "    \n",
    "    \n",
    "    arm_vehicle(mav)\n",
    "    takeoff_vehicle(mav, 25)\n",
    "    \n",
    "    for wp in survey_waypoints:\n",
    "        lat, lon, alt = wp\n",
    "        goto_waypoint_mavlink(mav, lat, lon, alt, threshold=2.0, timeout=60)\n",
    "    \n",
    "  \n",
    "    goto_waypoint_mavlink(mav, survey_midpoint[0], survey_midpoint[1], survey_midpoint[2], threshold=2.0, timeout=60)\n",
    "    print(\"Reached survey midpoint. Capturing image...\")\n",
    "    time.sleep(2)\n",
    "    photo_file = capture_photo(\"mission_photo.jpg\")\n",
    "    \n",
    "   \n",
    "    quadrant = process_image_yolo(photo_file)\n",
    "    \n",
    "   \n",
    "    if quadrant is None:\n",
    "        print(\"Elephant not detected. Initiating flyback to takeoff location.\")\n",
    "        for wp in reversed(survey_waypoints):\n",
    "            lat, lon, alt = wp\n",
    "            goto_waypoint_mavlink(mav, lat, lon, alt, threshold=2.0, timeout=60)\n",
    "     \n",
    "        land_vehicle(mav, takeoff_location[0], takeoff_location[1], target_alt=0)\n",
    "        print(\"Mission complete. Closing connection.\")\n",
    "        mav.close()\n",
    "        servo.stop()\n",
    "        GPIO.cleanup()\n",
    "        return\n",
    "\n",
    "    landing_locations = {\n",
    "        \"top_right\": (51.423553, -2.670839, 0),\n",
    "        \"top_left\":  (51.423623, -2.670878, 0),\n",
    "        \"bottom_left\": (51.423548, -2.671165, 0),\n",
    "        \"bottom_right\": (51.423482, -2.671122, 0)\n",
    "    }\n",
    "    landing_lat, landing_lon, landing_alt = landing_locations.get(quadrant, landing_locations[\"top_left\"])\n",
    "    \n",
    "    goto_waypoint_mavlink(mav, landing_lat, landing_lon, 5, threshold=2.0, timeout=60)\n",
    "    land_vehicle(mav, landing_lat, landing_lon, target_alt=0)\n",
    "  \n",
    "    print(\"Holding on ground for 60 seconds. Please release the payload manually.\")\n",
    "    time.sleep(60)\n",
    "    \n",
    "    print(\"Mission complete. Closing connection.\")\n",
    "    mav.close()\n",
    "    servo.stop()\n",
    "    GPIO.cleanup()\n",
    "\n",
    "if _name_ == \"_main_\":\n",
    "    try:\n",
    "        main()\n",
    "    except Exception as e:\n",
    "        print(\"An error occurred:\", e)\n",
    "        servo.stop()\n",
    "        GPIO.cleanup()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
